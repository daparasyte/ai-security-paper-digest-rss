<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI Security Paper Digest</title><link>https://kentaroh-toyoda.github.io/ai-security-paper-digest-rss/rss.xml</link><description>Curated papers on AI security from OpenAlex and ArXiv</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><lastBuildDate>Thu, 26 Jun 2025 22:08:36 +0000</lastBuildDate><item><title>Towards Provable (In)Secure Model Weight Release Schemes</title><link>https://arxiv.org/abs/2506.19874</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Introduces formal security definitions for model weight release schemes&lt;/li&gt;&lt;li&gt;Analyzes TaylorMLP and identifies parameter extraction vulnerability&lt;/li&gt;&lt;li&gt;Advocates for rigorous security evaluation in ML&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Paper Type&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Research&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Additional Information&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Authors: ['Xing Yang', 'Bingtao Wang', 'Yuhao Wang', 'Zimo Ji', 'Terry Jingchen Zhang', 'Wenyuan Jiang']&lt;/li&gt;&lt;li&gt;Tags: ['model extraction', 'security definitions', 'adversarial attacks', 'cryptography', 'ML security']&lt;/li&gt;&lt;/ul&gt;</description><guid isPermaLink="false">https://arxiv.org/abs/2506.19874</guid><pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate></item></channel></rss>